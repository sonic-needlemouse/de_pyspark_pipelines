{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Задание после вводной лекции\n",
        "\n",
        "## Задание первое -- запустить спарк приложение и вывести его настройки с помощью print()\n",
        "\n",
        "Первый шаг -- запустить параграф \"Задание 1\" с интерпретером spark. При этом запустится zeppelin interpreter, который запустит Spark Application на Hadoop Yarn. Запущенное спарк приложение отобразится в списке здесь [Yarn Application List](http://ca-spark-n-01.innoca.local:8088/ui2/#/yarn-apps/apps). Пока интерпретер работает, вам доступна SparkSession в переменной spark. Из неё можно, например, получить конфигурацию спарк приложения (задание 1)\n",
        "\n",
        "Если нажать на странице Yarn Application List на ваш application_id, откроется его страница в Yarn. На ней нужно найти ссылку Application Master, пройти по ней в Spark UI. Это интерфейс приложения Spark, который доступен только пока приложение работает. \n",
        "\n",
        "\n",
        "## Важно! На каждую тетрадку запускается новый интерпретер. По завершении работы обязательно останавливать спарк приложение вызовом spark.stop() для освобождения ресурсов кластера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "\n",
        "# нужно отфильтровать конфиги по маске spark.* и распечатать с помощью print()\n",
        "# должно получиться что-то вроде такого:\n",
        "# spark.shuffle.service.enabled: False\n",
        "\n",
        "\n",
        "list_with_configs = spark.sparkContext.getConf().getAll()\n",
        "list_with_configs\n",
        "for item in list_with_configs:\n",
        "    print(item[0], \":\", item[1]) if item[0].__contains__('spark') or item[0].__contains__('SPARK') else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%spark.pyspark\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "lecture_1_boris_sergeev"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
