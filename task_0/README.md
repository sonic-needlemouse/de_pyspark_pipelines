# Вводное задание (проверка соединения и доступа) на проверку доступа к Spark кластеру

## Обзор

Этот репозиторий содержит решения домашнего задания по настройке и использованию Apache Hadoop в Docker-контейнерах. Задание включает в себя создание и конфигурацию Hadoop HDFS, а также выполнение определенных операций с файлами в HDFS.

## Постановка задачи:

### Цели:
1. Первый шаг -- запустить параграф "Задание 1" с интерпретером spark.
2. Проверить запущенное спарк приложение в Yarn Application List. 
3. Отфильтровать конфиги по маске spark.* и распечатать с помощью print()

